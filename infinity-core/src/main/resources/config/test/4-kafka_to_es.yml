inputs:
  - Kafka:
      topic:
        test-topic: 2
      codec: json
      consumer_settings:
        bootstrap.servers: 10.10.10.10:9092
        value.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        key.deserializer: org.apache.kafka.common.serialization.StringDeserializer
        group.id: test-topic-consumer

    #写各类filter
    #filters:
    #  todo
filters:
  - Add:
      fields:
        index_name: 'logkit-render' # 也可以写freemarker表达式
  - Date:
      src: '@timestamp'
      formats:
        - "YYYY-MM-dd'T'HH:mm:ss.SSS'Z'"
        - "YYYY-MM-dd HH:mm:ss.SSS"
        - "YYYY-MM-dd HH:mm:ss"
      target: '@timestamp'
      timezone: "Asia/Shanghai"

  - Rename:
      fields:
        index_name: name
#        '[beat][hostname]': hostname

outputs:
  - Stdout: {}
  - RestElasticsearch:
      cluster: test_cluster
      hosts:
        - 10.9.47.13:10099
      index: 'test-topic-%{+YYYY.MM.dd}'
      #    document_id: ${id} # defautt null, generated by es
      bulk_actions: 10 #default 20000
      bulk_size: 1 # default 15 MB
      flush_interval: 1 # default 10 seconds
      #      concurrent_requests: 1 # default 0, concurrent_requests设置成大于0的数, 意思着多线程处理, 以我应用的经验,还有是一定OOM风险的,强烈建议设置为0
      timezone: "Asia/Shanghai" # defaut UTC 时区. 只用于生成索引名字的字符串格式化
      sniff: true #default true